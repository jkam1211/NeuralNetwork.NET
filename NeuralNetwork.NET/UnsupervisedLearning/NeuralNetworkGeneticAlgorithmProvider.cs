using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;
using JetBrains.Annotations;
using NeuralNetworkNET.Helpers;
using NeuralNetworkNET.Networks;
using NeuralNetworkNET.Networks.Implementations;
using NeuralNetworkNET.Networks.PublicAPIs;
using NeuralNetworkNET.UnsupervisedLearning.Misc;

namespace NeuralNetworkNET.UnsupervisedLearning
{
    /// <summary>
    /// A provider that uses a genetic algorithm to breed different species of neural networks to maximize a given fitness function
    /// </summary>
    public sealed class NeuralNetworkGeneticAlgorithmProvider
    {
        #region Fields and parameters

        /// <summary>
        /// Gets the size of the input layer
        /// </summary>
        public int InputLayerSize { get; }

        /// <summary>
        /// Gets the size of the output layer
        /// </summary>
        public int OutputLayerSize { get; }

        /// <summary>
        /// Gets the size of the population for the genetic algorithm
        /// </summary>
        public int PopulationSize { get; }

        /// <summary>
        /// Gets the mutation probability for each weight in the neural networks
        /// </summary>
        public int WeightsMutationRate { get; }

        /// <summary>
        /// Gets the number of best networks to copy over to each new generation
        /// </summary>
        public int EliteSamples { get; }

        /// <summary>
        /// Gets the number of nodes in each hidden layer
        /// </summary>
        [NotNull]
        public IReadOnlyList<int> HiddenLayers { get; }

        #endregion

        #region Genetic algorithm public parameters

        /// <summary>
        /// Gets the function used to evaluate the fitness of every generated network
        /// </summary>
        [NotNull]
        public FitnessDelegate FitnessFunction { get; }

        /// <summary>
        /// Gets or sets the callback action used to report the progress
        /// </summary>
        [CanBeNull]
        public IProgress<GeneticAlgorithmProgress> ProgressCallback { get; set; }

        /// <summary>
        /// Gets the number of the current generation since the provider instance was created
        /// </summary>
        public int Generation { get; private set; }

        /// <summary>
        /// Gets whether or not the provider instance is currently running the genetic algorithm
        /// </summary>
        public bool IsRunning => _Cts != null;

        #endregion

        #region Working set fields

        /// <summary>
        /// Gets the random instance used in the genetic algorithm
        /// </summary>
        private readonly Random RandomProvider = new Random();

        /// <summary>
        /// Gets the current population for the genetic algorithm
        /// </summary>
        private NeuralNetworkBase[] _Population;


        /// <summary>
        /// Gets the semaphore used to synchronize the genetic algorithm execution
        /// </summary>
        private readonly SemaphoreSlim RunningSemaphore = new SemaphoreSlim(1);

        /// <summary>
        /// Gets the cacellation token to stop the genetic algorithm
        /// </summary>
        private CancellationTokenSource _Cts;

        #endregion

        #region Best network

        private (INeuralNetwork, double) _BestResult;

        /// <summary>
        /// Gets or sets the current best result produced by the genetic algorithm
        /// </summary>
        private (INeuralNetwork, double) BestResult
        {
            get => _BestResult;
            set
            {
                (_, double previous) = _BestResult;
                (_, double next) = value;
                if (next > previous)
                {
                    _BestResult = value;
                    BestNetworkChanged?.Invoke(this, new GeneticAlgorithmBestNetworkChangedEventArgs(value.Item1, value.Item2));
                }
            }
        }

        /// <summary>
        /// Gets the maximum fitness score reached by the provider instance
        /// </summary>
        [PublicAPI]
        public double BestFitness => _BestResult.Item2;

        /// <summary>
        /// Gets the current best network generated by the provider
        /// </summary>
        [PublicAPI]
        [CanBeNull]
        public INeuralNetwork BestNetwork => BestResult.Item1;

        /// <summary>
        /// Callback called whenever the genetic algorithm produces a better neural network for the current fitness function
        /// </summary>
        public event EventHandler<GeneticAlgorithmBestNetworkChangedEventArgs> BestNetworkChanged;

        #endregion

        #region Initialization

        // Private constructor
        private NeuralNetworkGeneticAlgorithmProvider(
            [NotNull] FitnessDelegate fitnessFunction,
            int input, int output, [NotNull] IReadOnlyList<int> hiddenLayers,
            int population, int weightsMutationRate, int eliteSamples)
        {
            // Input checks
            if (input <= 0 || output <= 0)
            {
                throw new ArgumentOutOfRangeException("The input layer, the output layer and the first hidden layer must have at least one neuron each");
            }
            if (hiddenLayers.Any(n => n <= 0)) throw new ArgumentOutOfRangeException("The size of a hidden layer can't be negative");
            if (population <= 0) throw new ArgumentOutOfRangeException("The population must have at least one element");
            if (weightsMutationRate <= 0 || weightsMutationRate > 99) throw new ArgumentOutOfRangeException("The mutation rate must be between 0 and 100");
            if (eliteSamples < 0 || eliteSamples >= population)
            {
                throw new ArgumentOutOfRangeException("The number of elite samples must be a positive number less than or equal to the population size");
            }

            // Assign the fields
            FitnessFunction = fitnessFunction ?? throw new ArgumentNullException("The fitness function can't be null");
            InputLayerSize = input;
            OutputLayerSize = output;
            HiddenLayers = hiddenLayers;
            PopulationSize = population;
            WeightsMutationRate = weightsMutationRate;
            EliteSamples = eliteSamples;
        }

        /// <summary>
        /// Creates a new provider instance with no hidden layers
        /// </summary>
        /// <param name="fitnessFunction">The fitness function used to evaluate the neural networks</param>
        /// <param name="input">Number of inputs in the neural network</param>
        /// <param name="output">Number of outputs in the neural network</param>
        /// <param name="population">Number of networks in the population</param>
        /// <param name="weightsMutationRate">Probability for each weight mutation</param>
        /// <param name="eliteSamples">Number of best networks to copy in each generation</param>
        [PublicAPI]
        [ItemNotNull]
        public static Task<NeuralNetworkGeneticAlgorithmProvider> NewLinearPerceptronProviderAsync(
            [NotNull] FitnessDelegate fitnessFunction,
            int input, int output,
            int population, int weightsMutationRate, int eliteSamples)
        {
            return Task.Run(() =>
            {
                NeuralNetworkGeneticAlgorithmProvider provider = new NeuralNetworkGeneticAlgorithmProvider(fitnessFunction,
                    input, output, new int[0], population, weightsMutationRate, eliteSamples);
                provider._Population = provider.InitializePopulation();
                return provider;
            });
        }

        /// <summary>
        /// Creates a new provider instance with a single hidden neurons layer
        /// </summary>
        /// <param name="fitnessFunction">The fitness function used to evaluate the neural networks</param>
        /// <param name="input">Number of inputs in the neural network</param>
        /// <param name="output">Number of outputs in the neural network</param>
        /// <param name="size">Number of neurons in the hidden layer</param>
        /// <param name="population">Number of networks in the population</param>
        /// <param name="weightsMutationRate">Probability for each weight mutation</param>
        /// <param name="eliteSamples">Number of best networks to copy in each generation</param>
        [PublicAPI]
        [ItemNotNull]
        public static Task<NeuralNetworkGeneticAlgorithmProvider> NewSingleLayerNetworkProviderAsync(
            [NotNull] FitnessDelegate fitnessFunction,
            int input, int output, int size,
            int population, int weightsMutationRate, int eliteSamples)
        {
            return Task.Run(() =>
            {
                NeuralNetworkGeneticAlgorithmProvider provider = new NeuralNetworkGeneticAlgorithmProvider(fitnessFunction,
                    input, output, new[] { size }, population, weightsMutationRate, eliteSamples);
                provider._Population = provider.InitializePopulation();
                return provider;
            });
        }

        /// <summary>
        /// Creates a new provider instance with multiple hidden layers
        /// </summary>
        /// <param name="fitnessFunction">The fitness function used to evaluate the neural networks</param>
        /// <param name="input">Number of inputs in the neural network</param>
        /// <param name="output">Number of outputs in the neural network</param>
        /// <param name="hiddenLayers">Number of neurons in each hidden layer</param>
        /// <param name="population">Number of networks in the population</param>
        /// <param name="weightsMutationRate">Probability for each weight mutation</param>
        /// <param name="eliteSamples">Number of best networks to copy in each generation</param>
        [PublicAPI]
        [ItemNotNull]
        public static Task<NeuralNetworkGeneticAlgorithmProvider> NewMultilayerPerceptronProviderAsync(
            [NotNull] FitnessDelegate fitnessFunction,
            int input, int output, [NotNull] IReadOnlyList<int> hiddenLayers,
            int population, int weightsMutationRate, int eliteSamples)
        {
            return Task.Run(() =>
            {
                NeuralNetworkGeneticAlgorithmProvider provider = new NeuralNetworkGeneticAlgorithmProvider(fitnessFunction,
                    input, output, hiddenLayers, population, weightsMutationRate, eliteSamples);
                provider._Population = provider.InitializePopulation();
                return provider;
            });
        }

        #region Pre-initialized providers

        /* 
        
        // Helper method to get a provider instance
        private static NeuralNetworkGeneticAlgorithmProvider ReconstructInstance(
            FitnessDelegate fitnessFunction, INeuralNetwork network,
            int population, int weightsMutationRate, int eliteSamples)
        {
            // Reconstruct the original data
            NeuralNetworkGeneticAlgorithmProvider provider;
            if (network is TwoLayersNeuralNetwork)
            {
                TwoLayersNeuralNetwork twoLayers = (TwoLayersNeuralNetwork)network;
                provider = new NeuralNetworkGeneticAlgorithmProvider(
                    fitnessFunction, twoLayers.InputLayerSize, twoLayers.OutputLayerSize, twoLayers.HiddenLayerSize,
                    twoLayers.SecondHiddenLayerSize, twoLayers.Z1Threshold, twoLayers.Z2Threshold,
                    twoLayers.Z3Threshold,
                    population, weightsMutationRate, eliteSamples);
            }
            else
            {
                provider = new NeuralNetworkGeneticAlgorithmProvider(
                    fitnessFunction, network.InputLayerSize, network.OutputLayerSize, network.HiddenLayerSize,
                    0, network.Z1Threshold, network.Z2Threshold, null, population, weightsMutationRate, eliteSamples);
            }

            // Randomize the population
            NeuralNetworkBase[] initialPopulation = new NeuralNetworkBase[population];
            initialPopulation[0] = network;
            for (int i = 1; i < population - 1; i++) initialPopulation[i] = provider.MutateNetwork(network);
            return provider;
        }

        /// <summary>
        /// Creates a new instance from a serialized neural network
        /// </summary>
        /// <param name="fitnessFunction">The fitness function used to evaluate the neural networks</param>
        /// <param name="networkData">The serialized neural network to use to initialize the provider</param>
        /// <param name="population">Number of networks in the population</param>
        /// <param name="weightsMutationRate">Probability for each weight mutation</param>
        /// <param name="eliteSamples">Number of best networks to copy in each generation</param>
        public static Task<NeuralNetworkGeneticAlgorithmProvider> FromSerializedNetworkAsync(
            FitnessDelegate fitnessFunction, byte[] networkData,
            int population, int weightsMutationRate, int eliteSamples)
        {
            return Task.Run(() =>
            {
                // Try to deserialize the original network
                NeuralNetworkBase network = NeuralNetworkDeserializer.TryGetInstance(networkData) as NeuralNetworkBase;
                return network == null ? null : ReconstructInstance(fitnessFunction, network, population, weightsMutationRate, eliteSamples);
            });
        }

        /// <summary>
        /// Creates a new instance from a serialized neural network
        /// </summary>
        /// <param name="fitnessFunction">The fitness function used to evaluate the neural networks</param>
        /// <param name="network">The neural network to use to initialize the provider</param>
        /// <param name="population">Number of networks in the population</param>
        /// <param name="weightsMutationRate">Probability for each weight mutation</param>
        /// <param name="eliteSamples">Number of best networks to copy in each generation</param>
        public static Task<NeuralNetworkGeneticAlgorithmProvider> FromNetworkAsync(
            FitnessDelegate fitnessFunction, INeuralNetwork network,
            int population, int weightsMutationRate, int eliteSamples)
        {
            return Task.Run(() => ReconstructInstance(fitnessFunction, (NeuralNetworkBase)network, population, weightsMutationRate, eliteSamples));
        } */

        #endregion

        #endregion

        #region Public methods

        /// <summary>
        /// Starts the provider, returns true if the operation is successful
        /// </summary>
        [PublicAPI]
        public async Task<bool> StartAsync()
        {
            // Wait and check the current status
            await RunningSemaphore.WaitAsync();
            if (_Cts != null)
            {
                RunningSemaphore.Release();
                return false;
            }

            // Start the genetic algorithm
            _Cts = new CancellationTokenSource();
            BreedNetworks(_Cts.Token);
            RunningSemaphore.Release();
            return true;
        }

        /// <summary>
        /// Stops the provider, returns false if it wasn't running when the method was called
        /// </summary>
        [PublicAPI]
        public async Task<bool> StopAsync()
        {
            // Wait and check if the provider was running
            await RunningSemaphore.WaitAsync();
            if (_Cts == null)
            {
                RunningSemaphore.Release();
                return false;
            }

            // Stop the genetic algorithm
            _Cts.Cancel();
            _Cts = null;
            RunningSemaphore.Release();
            return true;
        }

        #endregion

        #region Genetic algorithm

        /// <summary>
        /// Initializes a new random population with the current parameters
        /// </summary>
        private NeuralNetworkBase[] InitializePopulation()
        {
            // Linear perceptron
            NeuralNetworkBase[] population = new NeuralNetworkBase[PopulationSize];
            if (HiddenLayers.Count == 0)
                for (int i = 0; i < PopulationSize; i++)
                    population[i] = LinearPerceptron.NewRandom(InputLayerSize, OutputLayerSize);

            // Single layer neural network
            else if (HiddenLayers.Count == 1)
                for (int i = 0; i < PopulationSize; i++)
                    population[i] = SingleLayerPerceptron.NewRandom(InputLayerSize, HiddenLayers[0], OutputLayerSize);
            {
                // Two layers if needed
                for (int i = 0; i < PopulationSize; i++)
                {
                   // population[i] = new TwoLayersNeuralNetwork(InputLayerSize, OutputLayerSize, FirstHiddenLayerSize,
                   //     SecondHiddenLayerSize, Z1Threshold, Z2Threshold, Z3Threshold, RandomProvider);
                }
            }
            return population;
        }

        /// <summary>
        /// Returns a new mutated network from the input network
        /// </summary>
        /// <param name="network">The input network</param>
        [NotNull]
        private static NeuralNetworkBase MutateNetwork([NotNull] NeuralNetworkBase network)
        {
            switch (network)
            {
                case SingleLayerPerceptron _:
                    double[]
                        w1w2 = network.SerializeWeights(),
                        w1w2r = w1w2.Randomize(0.5);
                    return LinearPerceptron.Deserialize(network.InputLayerSize, network.OutputLayerSize, w1w2r);
                case LinearPerceptron _:
                    double[]
                        w1 = network.SerializeWeights(),
                        w1r = w1.Randomize(0.5);
                    return LinearPerceptron.Deserialize(network.InputLayerSize, network.OutputLayerSize, w1r);
                default:
                    throw new NotImplementedException();
            }
        }

        /// <summary>
        /// Runs the genetic algorithm
        /// </summary>
        /// <param name="token">The cancellation token for the algorithm</param>
        private async void BreedNetworks(CancellationToken token)
        {
            // Loop until the token is cancelled
            while (!token.IsCancellationRequested)
            {
                // Test the current generation
                IEnumerable<Task<(NeuralNetworkBase, double)>> testing = _Population.Select(async (net, i) =>
                {
                    IEnumerable<ForwardFunction> opponents = _Population.Where((entry, pos) => pos != i).Select<NeuralNetworkBase, ForwardFunction>(entry => entry.Forward);
                    double fitness = await Task.Run(() => FitnessFunction(net.GetHashCode(), net.Forward, opponents), token);
                    return (net, fitness);
                });
                (NeuralNetworkBase, double)[] result = await Task.WhenAll(testing);

                // Iterate over all the results
                double tot = 0;
                (NeuralNetworkBase, double) bestResult = (null, 0);
                foreach ((NeuralNetworkBase net, double score) in result)
                {
                    // Get the best score and the total
                    (NeuralNetworkBase previous, double previousScore) = bestResult;
                    if (previous == null || score > previousScore)
                    {
                        bestResult = (net, score);
                    }
                    tot += score;
                }
                if (bestResult.Item1 == null) throw new InvalidOperationException();
                if (bestResult.Item2 > BestFitness) BestResult = bestResult;

                // Invoke the callback if possible
                ProgressCallback?.Report(new GeneticAlgorithmProgress(Generation, bestResult.Item2, tot / PopulationSize, BestFitness));
                Generation++;

                // Iterate over the results and populate the mating pool
                (NeuralNetworkBase, double)[] matingPool = new (NeuralNetworkBase, double)[PopulationSize];
                for (int i = 0; i < PopulationSize; i++)
                {
                    // Pick a random mate
                    int b;
                    do
                    {
                        b = RandomProvider.Next(PopulationSize);
                    } while (i == b);

                    // Add the best one to the pool
                    matingPool[i] = result[i].Item2 > result[b].Item2 ? result[i] : result[b];
                }

                // Initialize the children list and select the elite
                List<NeuralNetworkBase> children = new List<NeuralNetworkBase>();
                children.AddRange(matingPool.OrderByDescending(r => r.Item2).Take(EliteSamples).Select(r => r.Item1));

                // Filter the mating pool to skip the worst results
                NeuralNetworkBase[] filtered = matingPool.OrderBy(r => r.Item2).Skip(EliteSamples).Select(r => r.Item1).ToArray();
                for (int i = 0; i < filtered.Length; i++)
                {
                    // Select the parents for the new child
                    int a, b;
                    do
                    {
                        a = RandomProvider.Next(filtered.Length);
                        b = RandomProvider.Next(filtered.Length);
                    } while (a == b);

                    // Two points crossover
                    children.Add(filtered[a].Crossover(filtered[b], RandomProvider));
                }
                if (children.Count != PopulationSize) Debugger.Break();

                // Queue and run all the current mutation
                IEnumerable<Task<NeuralNetworkBase>> mutation = children.Select(child => Task.Run(() => MutateNetwork(child), token));
                _Population = await Task.WhenAll(mutation);
            }
        }

        #endregion
    }
}
